<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>罗素：我为什么而活</title>
      <link href="/blog/what-i-have-lived-for-by-russell.html"/>
      <url>/blog/what-i-have-lived-for-by-russell.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文摘自《我为什么而活着》，《我为什么而活着》是《罗素自传》的序言，作者是伯特兰·罗素。</p></blockquote><h2 id="中文译文"><a href="#中文译文" class="headerlink" title="中文译文"></a>中文译文</h2><p>对爱情的渴望，对知识的追求，对人类苦难不可遏制的同情心，这三种纯洁而无比强烈的激情支配着我的一生。这三种激情，就像飓风一样，在深深的苦海上，肆意地把我吹来吹去，吹到濒临绝望的边缘。</p><p>我寻求爱情，首先因为爱情给我带来狂喜，它如此强烈以致我经常愿意为了几小时的欢愉而牺牲生命中的其他一切。我寻求爱情，其次是因为爱情可以解除孤寂一—那是一颗震颤的心，在世界的边缘，俯瞰那冰冷死寂、深不可测的深渊。我寻求爱情，最后是因为在爱情的结合中，我看到圣徒和诗人们所想像的天堂景象的神秘缩影。这就是我所寻求的，虽然它对人生似乎过于美好，然而最终我还是得到了它。</p><p>我以同样的热情寻求知识，我渴望了解人的心灵。我渴望知道星星为什么闪闪发光，我试图理解毕达哥拉斯的思想威力，即数字支配着万物流转。这方面我获得一些成就，然而并不多。</p><p>爱情和知识，尽其可能地把我引上天堂，但是同情心总把我带回尘世。痛苦的呼唤经常在我心中回荡，饥饿的儿童，被压迫被折磨者，被儿女视为负担的无助的老人以及充满孤寂、贫穷和痛苦的整个世界，都是对人类应有生活的嘲讽。我渴望减轻这些不幸，但是我无能为力，而且我自己也深受其害。</p><p>这就是我的一生，我觉得值得为它活着。如果有机会的话，我还乐意再活一次。</p><h2 id="英文原文"><a href="#英文原文" class="headerlink" title="英文原文"></a>英文原文</h2><p>《What I Have Lived For》 by Bertrand Russell</p><p>Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a great ocean of anguish, reaching to the very verge of despair.</p><p>I have sought love, first, because it brings ecstasy - ecstasy so great that I would often have sacrificed all the rest of life for a few hours of this joy. I have sought it, next, because it relieves loneliness–that terrible loneliness in which one shivering consciousness looks over the rim of the world into the cold unfathomable lifeless abyss. I have sought it finally, because in the union of love I have seen, in a mystic miniature, the prefiguring vision of the heaven that saints and poets have imagined. This is what I sought, and though it might seem too good for human life, this is what–at last–I have found.</p><p>With equal passion I have sought knowledge. I have wished to understand the hearts of men. I have wished to know why the stars shine. And I have tried to apprehend the Pythagorean power by which number holds sway above the flux. A little of this, but not much, I have achieved.</p><p>Love and knowledge, so far as they were possible, led upward toward the heavens. But always pity brought me back to earth. Echoes of cries of pain reverberate in my heart. Children in famine, victims tortured by oppressors, helpless old people a burden to their sons, and the whole world of loneliness, poverty, and pain make a mockery of what human life should be. I long to alleviate this evil, but I cannot, and I too suffer.</p><p>This has been my life. I have found it worth living, and would gladly live it again if the chance were offered me.</p>]]></content>
      
      
      <categories>
          
          <category> 励志 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 罗素 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>李开复：追随我心</title>
      <link href="/blog/follow-your-heart-by-likaifu.html"/>
      <url>/blog/follow-your-heart-by-likaifu.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>全文摘自李开复相关传记，《追随我心》，作者不详。</p></blockquote><p>并不很久的以前，也就在 1979 年到 1980 年间，在哥伦比亚大学，两个政治科学系大一的新生，在课堂上总是没精打采。其中一个是来自台湾的华裔，喜欢窝在教室左后方的一隅，听得无趣，索性呼呼大睡。这个男孩叫李开复，此君并非厌学，而是对政治科学越来越不感兴趣。蹉跎到大二下学期，他终于决定快刀斩乱麻——转系，改学自己感兴趣的计算机。</p><p>兴趣是什么？兴趣就意味着天赋。李开复在计算机系如鱼得水，左右逢源，两年后毕业，成绩居全系之首。这样的学生用不着按部就班。在教授的推荐下，李开复进入在计算机领域独领风骚的卡内基•梅隆大学，直接攻读博士。计算机学院的院长找他谈话，劈头就问：“读博士的目的是什么？”李开复大声答：“我从大学带走的将是一篇改变世界的、顶尖的博士论文。”院长予以纠正，说：“你从这儿带走的最有价值的东西，不是一篇论文，而是你分析、思考的能力，研究、发现真理的经验，以及科学家的胸怀。这样，当你有一天改变研究方向，依然可以在任何一个新的领域出类拔萃。”李开复选定语音识别为攻读方向，经过一年“热恋”，他发现专家系统其冷如冰，远不如统计学有情有义。李开复决心“移情别恋”。他担心导师发怒，谁知得到的回答竟是：“开复，你对专家系统和统计的观点，我是不赞同的，但我可以支持你用统计的方法去做，因为我相信科学没有绝对的对错，我们都是平等的。而且，我更相信一个富有激情的人可以找到更好的解决方案。”李开复从导师的大度悟到科学的真谛，他全力以赴，放手一搏。３年过去了，李开复的研究成果及博士论文，引发了那年语音世界最大的冲击波。26 岁的李开复功成名就，成为卡内基•梅隆大学最年轻的副教授。天之骄子，有尊严，有地位，有课题，有经费，出任大公司顾问，飞赴各地讲学，包括去他的祖籍之邦、魂之所系的祖国大陆。</p><p>“让世界因你而不同！”这是李开复埋在心底多年的梦想。1990 年，苹果公司的一个邀请电话让李开复开始审视自己：“开复，你是想一辈子写一堆像废纸一样的学术论文，还是想真正地改变世界？”面对苹果公司的召唤，李开复旋即做出回应，走出象牙塔，加盟“改变世界”的大军。在苹果公司，李开复感受到了从纸上谈兵转入实战的无穷乐趣。1995 年，33 岁的李开复出任苹果公司的副总裁。</p><p>但是他仍然不满足，依然要跳槽，因为硅谷的另一家公司 SGI 发出了更有诱惑力的邀请——“你想做什么，然后我们根据你的兴趣对公司进行改组。”不是他们缺什么人才，让你去填补，而是诚恳地询问你需要什么平台，以便为你量身搭建。这样的机遇，李开复岂能错过！双方一拍即合，　1996 年７月，李开复跳槽去了 SGI 。李开复奉行“自己设计自己”的人生信条，怎奈 SGI 是一家硬件公司，开复的长处却在软件开发，这就等于在篮球场上跑马，任是赤兔、骅骝，也撒不开四蹄。日复一日，李开复萌生去意。对于下一个选择，他立下两条标准：一是做软件，二是去中国。</p><p>机会来了。其实机会无处不在，就看你有没有做好准备。彼时，比尔•盖茨创立的微软王国要把触角伸向中国，李开复成为它的不二人选。时间：1998 年金秋；职务：微软中国研究院院长。李开复在中国市场的开拓，值得写部书来描述，那是一种完全不同的创新理念、绝对领先的科学技术在神州大地生根发芽。微软只是起用了一个人，就开拓了中国市场；李开复只是“追随我心”，就一跃成为微软王国的副总裁。在你我想来，这该是李开复的最后一站。在微软占据高位，与比尔•盖茨亲密共事，坐拥财富和风光，“花迎喜气皆知笑，鸟识欢心亦解歌”。人生至此，夫复何求？李开复不这么想，他后来回忆：“我如同一部庞大机器上的零件，在中规中矩、没有任何发挥空间的环境下运行着。这是一个随时随地都可以被替换的光鲜零件。那种价值的缺失感以及精神上的落寞占据了我的内心。”微软既然已无成长空间，那就走吧！到哪儿去？他相中了 Google。但他清醒地意识到，管理更多的人马，不是自己的所爱，他渴望从无到有的创新，而不是经营一个巨无霸。于是，在2009 年９月，李开复又一次选择潇洒地离去。向总部递交辞呈之际，Google 高管艾伦•尤斯塔斯试图用更优厚的条件予以挽留。李开复真诚地说：“我的人生还有一个缺憾没有实现，现在得去弥补。我可能创办一家‘创新工场’，和中国青年一起创造新的技术奇迹。”</p><p>如今，李开复正在按照他本人的意愿，在神州大地进行“创新工场”试验。他会成功吗？我想这是毫无疑问的，也是次要又次要的，那么，最主要的一点是什么呢？诚如他自己所言：“人生在世时间非常短，如果你总是不敢做想做的事情，那么一生过去了，你留下来的只有悔恨，只有懊恼。”“我步入丛林，因为我希望生活得有意义，我希望活得深刻，并汲取生命中所有的精华，然后从中学习，以免让我在生命终结时，才发现自己从来没有活过。”</p>]]></content>
      
      
      <categories>
          
          <category> 励志 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 李开复 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新微博通知 chrome 扩展使用介绍</title>
      <link href="/blog/new-weibo-notify-chrome-extension.html"/>
      <url>/blog/new-weibo-notify-chrome-extension.html</url>
      
        <content type="html"><![CDATA[<h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>博主开发的新微博通知助手，已上架谷歌扩展商城：<a href="https://chrome.google.com/webstore/detail/%E5%BE%AE%E5%8D%9A%E9%80%9A%E7%9F%A5%E5%8A%A9%E6%89%8B/cpmlmjdimlnhgnakcjfmbmfglhkaoago?hl=zh-CN">点击前往商城免费安装</a>。</p><p>它的作用是接收指定微博用户的最新微博通知（不包括置顶微博）。</p><p>它的特色是不需要 Cookie，不需要登录无状态即可收到桌面通知。</p><p>它的操作也特别简单，自动解析 uid，点击保存即可。</p><p><img src="https://s2.loli.net/2022/01/20/ygVbRSAwGJXvO7Y.png" alt="chrome_extension_zip.png"></p><p>然后插件就会定时 20s 去轮询这个人的微博状态，一有它的最新微博就会有系统级的桌面通知。</p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>1、注意解析的地址栏，必须是微博数字 uid，微博用户自定义域名的 id 不行。比如谢娜的微博主页自定义成 xiena，但是每一个微博用户都有数字 uid 的，怎么找呢，秘诀就是在这个微博用户任意一条的微博的用户名上右键在新 tab 打开链接，然后地址栏就有数字 uid 了。</p><p>这样自动解析成功，点击保存就能接受新微博通知了。</p><p>无论自动解析成否，也可以手动输入数字 uid；可以在上图 2 处输入框输入，也可以在上图 3 处 add uid 输入。保存的 uid 实时显示在 3 处浅绿色标签，一个 uid 对应一个标签。可以点击标签上的 X 删除 uid。</p><p>2、明明保存了配置，显示添加成功，也有新微博了，就是收不到通知？</p><p>可能在电脑的设置里关闭了 Chrome 的桌面通知权限？打开即可。</p><p>浏览器在后台或前台运行的话，能实时通知，如果关闭了，下次打开也能收到最新通知。</p><p>如果没网络那就肯定收不到通知了。</p><p>3、轮询时间不可设置</p><p>轮询时间也不能设置，固定 20s。何哉？因为本插件的定位是非常克制的，没有 cookie，登录，无状态。如果想同时接收很多人的通知，建议直接在浏览器打开 weibo.com。本插件的最佳食用方式是少量的 uid，uid 对应的博主不频繁发微博这种。</p>]]></content>
      
      
      <categories>
          
          <category> Chrome Extension </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博 </tag>
            
            <tag> chrome 扩展 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈微博评论水军和异常流量</title>
      <link href="/blog/weibo-comment-robot-analysis.html"/>
      <url>/blog/weibo-comment-robot-analysis.html</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>近年来，微博评论区的异常评论流量现象甚嚣尘上，背后是大量的营销账号的扰乱视听以及作为他们的傀儡的水军账号的推波助澜，本篇利用微博评论爬虫采集的公开数据，简单分析了这些现象的一些表征和原因。</p><h3 id="数说"><a href="#数说" class="headerlink" title="数说"></a>数说</h3><p>以人民日报发表的关于 <strong>#吴亦凡被批捕#</strong> 这条微博及其评论数据为例子。</p><p><img src="https://s2.loli.net/2022/01/20/AXRmgYvsIUJOHdb.png" alt="人民日报.png"></p><p>网页显示有近 18w 条微博，实际抓取去重后有 10w 稍有余的数据，包括根评论和回复，后文分析评论时，仅针对分析发博一天内的评论。抓取保存的评论字段信息如下</p><table><thead><tr><th align="center">字段名</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">parent_cid</td><td align="center">该回复所属的根评论 id，只有回复评论有值，根评论为空</td></tr><tr><td align="center">cid</td><td align="center">评论 id</td></tr><tr><td align="center">time</td><td align="center">评论发表时间</td></tr><tr><td align="center">text</td><td align="center">评论内容</td></tr><tr><td align="center">like_count</td><td align="center">评论点赞数</td></tr><tr><td align="center">reply_count</td><td align="center">该根评论有多少条回复评论，只有根评论有值，回复评论为0</td></tr><tr><td align="center">uid</td><td align="center">评论者 id</td></tr><tr><td align="center">username</td><td align="center">评论者用户名</td></tr><tr><td align="center">following</td><td align="center">评论者关注数</td></tr><tr><td align="center">followed</td><td align="center">评论者粉丝数</td></tr><tr><td align="center">gender</td><td align="center">评论者性别</td></tr></tbody></table><p>第一步，可视化该条微博发布后一天内每分钟新发评论数量时间线。</p><p><img src="https://s2.loli.net/2022/01/20/dIz632LbKUP7e1C.png" alt="发博后每分钟评论数.png"></p><p>每分钟评论数在短时间内指数型急剧上升，最后又以一象限双曲线形式下降，符合常理认知。同时可以看出，在发博时间 2021/08/16 20:30 过去 840mins，也就是发博 16 小时后，2021/08/17 10:30 时有个极大值，why？迫于本篇推送选题的压力，我马上想到了可能是水军账号这个时候营业了，但是我分析了这个时间段发布评论的用户，肉眼可见几乎没有水军账号。于是乎，我翻开了微博的历史热搜数据，发现在这个时间点，#都美竹感谢朝阳公安和粉丝# 这个话题冲到了热搜第一，很显然，是由于该关联话题的热度扩散到了这条微博。</p><p><img src="https://s2.loli.net/2022/01/20/SYlnov7ZT8JjrMO.png" alt="历史热搜.png"></p><p>如果查证历史热搜数据该时间点无相关热搜，且几乎没有观察到该时间点附近评论营销水军内容，那么下降曲线就会是完美的一象限双曲线；否则就需要确定是相关热搜或者是营销水军，亦或者是它们共同作用的结果。</p><p>第二步，怎么大致判断评论中水军账号呢，我的做法是 group_by uid。</p><p>分析结果显示，一天之内，一个账号最多针对该微博发布了 26 条评论，发布 10 条评论以上的账号多达 30 余人，这些账号具有一定的营销号或水军嫌疑，目前只能手动点开微博主页浏览去确定，长期地，我想输出一个模型，根据 uid 判断账号是否是营销号或者水军账号，目前的想法就是根据它的发博连续性，关注粉丝之比，账号新旧程序等维度考量，大家有好想法欢迎留言。</p><p>最后可视化每分钟评论的平均文本长度如下。</p><p><img src="https://s2.loli.net/2022/01/20/gvCaqyJENzZriuj.png" alt="发博后每分钟评论平均长度.png"></p><p>处理时去除了 html 标签表情等非文本内容，但是上图依旧有很大的锯齿，应该用中值滤波处理之，不过走势应该不会变。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1、微博历史热搜数据：<a href="https://www.weibotop.cn/2.0/">https://www.weibotop.cn/2.0/</a></p><p>2、研究报告 | 微博评论中的水军异常流量分析：<a href="https://zhuanlan.zhihu.com/p/436967668">https://zhuanlan.zhihu.com/p/436967668</a></p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博评论 </tag>
            
            <tag> 水军 </tag>
            
            <tag> 营销号 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博明星关系网络可视化</title>
      <link href="/blog/weibo-superstar-relation-network-visual.html"/>
      <url>/blog/weibo-superstar-relation-network-visual.html</url>
      
        <content type="html"><![CDATA[<p>抓取微博指定用户的关注信息，并做了一定的可视化工作。下面以抓取明星关注为例，阐述从抓取数据，到关系网络的构造，最后使用 gephi 可视化的全流程。</p><p>第一步，以一个<strong>给定的明星 uid 为起点，爬取它的关注，接着爬关注的关注</strong>…从形式上看是一个<strong>递归的网络</strong>，所以设计了一个<strong>递归的爬虫</strong>，可以指定抓取指定的层数，断网或其他出错可以从上次爬到的地方继续；一般来说 3 层就非常多，以一个明星关注 100 个明星为例，第一层只有起点明星，第二层有 100 个明星，第三层就有 10000 个明星了，我使用<strong>杨幂</strong>的 uid 为起点，抓取 3 层网络，实测抓到了 2w+ 明星，20w+ 对明星关注关系，最后随机抽了 5000 条关注关系，2000 余明星。</p><p>第二步，根据上一步得到的数据构造<strong>关系矩阵</strong>，方便 gephi 可视化输入。这个关系矩阵需要两个 csv 文件表示，一个节点 <strong>nodes.csv</strong> 文件，另一个边表 <strong>edges.csv</strong> 文件。</p><p>nodes.csv 四个字段，id 即该明星的微博 userId，label 是其名字，weight 是在关系网络中被关注的次数，class 是 <strong>louvain</strong> 聚类的结果。</p><p>edges.csv 三个字段：source,target,weight，分别对应边的起点、终点、权重。</p><p>gephi 最终的效果图示：</p><p><img src="https://s2.loli.net/2022/01/20/CD1jH6aoOyE5bFN.png" alt="全景图.png"></p><p><img src="https://s2.loli.net/2022/01/20/jKC7VkRoaApzu84.png" alt="网络边缘放大图.png"></p><p><img src="https://s2.loli.net/2022/01/20/Gk7P5DENsSVH9Q4.png" alt="网络中心放大图.png"></p><p>谁是十八线，谁是一线，一目了然，各位明星，如有冒犯，纯属无心之举。</p><p>动态效果可以参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=593321690&bvid=BV1dq4y1k7g8&cid=488583955&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html">https://buyixiao.github.io/blog/weibo-superstar-relation-network-visual.html</a></p><p>转载需注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 可视化 </tag>
            
            <tag> 关系网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微博转发网络可视化构建</title>
      <link href="/blog/weibo-forward-network-visual.html"/>
      <url>/blog/weibo-forward-network-visual.html</url>
      
        <content type="html"><![CDATA[<p>以敲钟人李文亮英雄的最后一条微博为例子，使用 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E8%BD%AC%E5%8F%91%E7%88%AC%E8%99%AB">新版微博转发爬虫</a> 抓取微博的具体转发信息,，抓取到 10w+ 的转发信息。</p><p>然后使用 <strong>pyecharts</strong> 构建了该条微博的 N 层转发关系网络。</p><p>依次取 N = 1,2,3,4，构建的网络图示：</p><div class="fj-gallery"><p><img src="https://s2.loli.net/2022/01/20/6W7qFOMVakQt12G.png" alt="n1.png"><br><img src="https://s2.loli.net/2022/01/20/UbLRrJdM3uZs1KY.png" alt="n4.png"><br><img src="https://s2.loli.net/2022/01/20/bYAP5xIMSrgmkis.png" alt="n2.png"><br><img src="https://s2.loli.net/2022/01/20/x8Oaz59lwZSdJrf.png" alt="n3.png"></p>          </div><p>动态效果可以参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=550803158&bvid=BV1Yq4y1c7TU&cid=488591630&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-forward-network-visual.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-forward-network-visual.html">https://buyixiao.github.io/blog/weibo-forward-network-visual.html</a></p><p>转载需注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> 可视化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博关系网络 </tag>
            
            <tag> 可视化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 中的 pyd 和 pyc 文件</title>
      <link href="/blog/pyd-pyc-summary.html"/>
      <url>/blog/pyd-pyc-summary.html</url>
      
        <content type="html"><![CDATA[<h2 id="pyd-特点及生成方式"><a href="#pyd-特点及生成方式" class="headerlink" title="pyd 特点及生成方式"></a>pyd 特点及生成方式</h2><p>我们知道 <strong>windows 系统有许多 DLL 后缀的文件，即动态链接库，在运行时链接到调用程序</strong>。在运行时链接到 DLL 之类的库的主要优点是，它可以促进代码重用，模块化体系结构和更快的程序启动。结果，DLL 在 Windows 操作系统周围提供了许多功能。<strong>pyd 这个 d 就是取自于 DLL，只能运行在 windows 系统上</strong>。</p><p>假设我们有一个 demo.py，想要打成 demo.pyd；首先需要在 <strong>demo.py 同目录下新建个</strong> <strong>setup.py</strong> <strong>文件</strong>，内容如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> Cython.Build <span class="keyword">import</span> cythonize</span><br><span class="line">setup(ext_modules=cythonize(<span class="string">&quot;demo.py&quot;</span>))</span><br></pre></td></tr></table></figure><p>然后在命令行或终端 cd 到这个目录下，输入一行命令之</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build_ext --inplace</span><br></pre></td></tr></table></figure><p>当前目录下就会生成<strong>一个 build 文件夹，一个 .c 文件，还有我们的主人翁 .pyd 文件</strong>，<strong>自动生成的名字****并不是 demo.pyd</strong>，而是 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">demo.cp36-win_amd64.pyd</span><br></pre></td></tr></table></figure><p><strong>这个 cp36 和 win_amd64 视 python 版本和操作系统而定。我们需要把它改成 demo.pyd，注意，是只能改成 demo.pyd；改成其他任何名字都不行，使用时会 import error。使用该 pyd 方式如下：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import demofrom demo import &#123;&#123;类名|函数名&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="pyc-特点及生成方式"><a href="#pyc-特点及生成方式" class="headerlink" title="pyc 特点及生成方式"></a>pyc 特点及生成方式</h2><p>而我们<strong>安装的 python 目录下有许多 pyc 文件，这个 c 是编译 compile 过的意思</strong>，可以使用 python 解释器编译 py 文件 成 pyc 字节码文件。使用 pyc 可以加快程序的加载速度，而不能加快程序的实际执行速度，这就是解释为什么我们<strong>安装 python 目录很多第三方库下是 pyc 文件的原因，因为它可以使得 import 一些第三方库的速度加快</strong>。由于 .pyc 文件是编译好的字节码，<strong>它是独立于平台的，因此可以在不同体系结构的计算机之间共享</strong>。其实还有一个和 pyc 类似的字节码文件 pyo，一般 pyo 替代未经优化而创建的 pyc 文件，这里就不展开了~</p><p>使用下面一行命令就能<strong>将当前目录下的所有 py 文件打成 pyc</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m compileall ./</span><br></pre></td></tr></table></figure><p><strong>pyc 的改名规则和 import 使用同 pyd !!!</strong></p><p>还有一点需要注意的是，由于 pyc 是由<strong>特定的 python 解析器生成的</strong>，它虽然能跨平台，但是不能跨版本，也<strong>只能运行在特定的 Python 版本上</strong>。如果 Python 版本不对，它会报 ImportError: bad magic number 错误。</p><h2 id="Pycharm-文件目录默认不索引-pyc"><a href="#Pycharm-文件目录默认不索引-pyc" class="headerlink" title="Pycharm 文件目录默认不索引 pyc"></a>Pycharm 文件目录默认不索引 pyc</h2><p> <strong>pyc 文件放到 Pycharm 中并不会显示它的存在？，但是确实实在存在于我们的文件夹之中的</strong>。</p><p>这是为什么呢？我猜测是 Pycharm 把 pyc exclude 排除显示了，上图 Pycharm 的 External Libraries 就是我们的 python 解析器，它有许许多多 pyc，如果全部显示。那么 index 索引将会非常大，严重会导致电脑卡死。</p><p>但是 pyd 就没有这种问题~</p><p>如不足之处欢迎批评指正~</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pyd </tag>
            
            <tag> pyc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【稳定可用 | 2022最新】微博超级爬虫</title>
      <link href="/blog/weibo-super-spider.html"/>
      <url>/blog/weibo-super-spider.html</url>
      
        <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本文是微博超级爬虫系列 2022 最新最全指南。</p><p>微博超级爬虫系列的仓库地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider">https://github.com/Python3Spiders/WeiboSuperSpider</a></p><p>之前的连载全部在公众号，但是由于爬虫时常修改，公众号发文只能修改一次，故开此篇，保持更新！</p><p>相关开源代码仅为相关数据研究用，不做任何加速，没有 ip 代理，请勿用作其他用途，由此产生的法律风险本人概不承担。</p><p>相关未开源代码均为 pyd 或者 pyc 文件（不了解 pyd 或者 pyc 文件的读者 <a href="https://buyixiao.github.io/blog/pyd-pyc-summary">点击这里</a>，pyd 只兼容 win 系统，pyc 则可以兼容 win/mac/linux ，也没有任何加速或 ip 代理。</p><p><font color="red">运行本项目前，请确保已经关闭了 vpn 或者加速器，或者代理模式设置成 PAC 模式。</p><p>运行本项目的任何 py 文件，由于相关语法限制，python 版本大于等于 3.6 即可，32 bit or 64 bit 均可。</p><p>运行本项目的任何 pyd or pyc 文件，由于特有文件限制，请确保 python 环境是 python3.6.6 64 bit。</font></p><p>还有一点，需要注意的是，微博的唯一标识 id 有两种形式。纯数字和数字+字母形式，这两者可以相互转化。转化的代码在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E5%BE%AE%E5%8D%9A%E4%B8%A4%E7%A7%8D-id-%E7%9B%B8%E4%BA%92%E8%BD%AC%E5%8C%96%E4%BB%A3%E7%A0%81">点我直达</a>，遇到相关问题时查阅即可。</p><h2 id="单功能微博爬虫"><a href="#单功能微博爬虫" class="headerlink" title="单功能微博爬虫"></a>单功能微博爬虫</h2><p>只需要抓取一个用户的所有微博或文章，一个关键词或者话题的特定时间段的微博，一个位置签到的最新微博，特定微博的转发，评论，点赞等功能之一的读者，可以只参考此部分。</p><h3 id="用户抓取系列"><a href="#用户抓取系列" class="headerlink" title="用户抓取系列"></a>用户抓取系列</h3><h4 id="用户微博爬虫"><a href="#用户微博爬虫" class="headerlink" title="用户微博爬虫"></a>用户微博爬虫</h4><p>见名知意，抓取一个用户的所有微博，针对 weibo.cn 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserScrapy.py">WeiboUserScrapy.py</a></p><p>运行代码需要安装的库罗列如下：</p><blockquote><p>pip install requests</p><p>pip install lxml</p></blockquote><div class="note warning simple"><p>pip install 成功了还报错 module not found？<a href="https://buyixiao.github.io/blog/pip-install-success-import-fail.html">点击这里</a></p></div><p>csv 结果文件，保存在代码目录下的 user 文件夹中，保存字段格式如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">wid</td><td align="center">数字 + 字母格式的微博唯一标识，可与纯数字形式 id 互转，<a href=""></a></td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">image_urls</td><td align="center">图片链接，以英文空格分隔多个图片链接</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">comment_num</td><td align="center">评论数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr><tr><td align="center">is_origin</td><td align="center">是否是原创微博</td></tr><tr><td align="center">origin_img_urls</td><td align="center">被转发微博图片链接</td></tr></tbody></table><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=806111483&bvid=BV1934y127ZM&cid=425810536&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h4 id="微博文章爬虫"><a href="#微博文章爬虫" class="headerlink" title="微博文章爬虫"></a>微博文章爬虫</h4><p>在微博上发布的内容有的短文本+图片（也就是微博），还有<strong>文章</strong>等形式，微博文章爬虫<strong>爬取用户的所有文章</strong>。有<strong>文章标题，id，内容，发布时间，阅读数，评论数，点赞数，图片链接</strong>等字段或信息。</p><p>针对 weibo.com 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboComPostSpider.py">WeiboComPostSpider.py</a></p><p>cookie 获取及更多信息可以参考：<a href="https://mp.weixin.qq.com/s/2Amq-jaQPXgZluga_7kTdQ">爬取微博用户所有文章的爬虫</a></p><h4 id="用户信息爬虫"><a href="#用户信息爬虫" class="headerlink" title="用户信息爬虫"></a>用户信息爬虫</h4><p>微博用户信息爬虫指的是，根据微博用户 id，抓取用户的<strong>阳光信用、性别、地区、学校、公司等信息</strong>。</p><p>针对 weibo.com 站点，代码全部开源在 WeiboSuperSpider 的 github 仓库地址，功能独立版文件夹下，取名 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboUserInfoSpider.py">WeiboUserInfoSpider</a></p><p><strong>拿到代码后需要填一下 headers 里面的</strong> <strong>cookie</strong>，随便打开 weibo.com 站点里一个人的主页，比如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://weibo.com/u/1764201374</span><br></pre></td></tr></table></figure><p>也可以是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://weibo.com/xiena</span><br></pre></td></tr></table></figure><p>这种微博用户自定义形式，然后 F12 开始找 <strong>info</strong> 或者 <strong>detail</strong> 这两个 path 之一，复制它们的 cookie 即可。</p><p>有关该爬虫更多信息可以参考：<a href="https://mp.weixin.qq.com/s/8_1pyLs5XcA3h3lL6RXIvg">超级方便的微博用户信息爬虫</a></p><h4 id="用户搜索爬虫"><a href="#用户搜索爬虫" class="headerlink" title="用户搜索爬虫"></a>用户搜索爬虫</h4><p>微博用户信息爬虫是根据微博用户 Uid 来抓取公开的用户微博信息，但是很多时候，我们可能只知道这个用户的微博名字，并不知道 Uid，用户搜索爬虫就是完成从微博用户名到 Uid 的转换。</p><p>针对 weibo.com 站点，代码地址在 <a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/SearchUser.py">SearchUser.py</a></p><p>cookie 获取及更多信息可以参考：<a href="https://mp.weixin.qq.com/s/-ktBld4T_MyUiEF7sWfX5A">微博搜索用户爬虫</a></p><h3 id="话题关键词系列"><a href="#话题关键词系列" class="headerlink" title="话题关键词系列"></a>话题关键词系列</h3><p>首先必须搞清楚微博的关键词、话题、超话这三者的区别。</p><p>首先 <strong>#buyixiao#</strong> 这个就是话题， 而 <strong>buyixiao</strong> 是关键词；使用关键词可以同时搜到同名话题，话题却不能搜到同名关键词。</p><p>话题和关键词区别明了，下面看 <a href="https://mp.weixin.qq.com/s/bfFa3BQPIdfo2aLlR9i0ng">关键词话题 和 超话的区别</a> 。</p><p>本爬虫只只能抓取关键词或话题，超话后续有精力再开发。抓取保存的结果 csv 文件字段格式如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">mid</td><td align="center">纯数字形式的微博唯一标识，可与字母+数字形式 id 互转</td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">user_name</td><td align="center">微博作者名</td></tr><tr><td align="center">user_link</td><td align="center">微博作者链接</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">image_urls</td><td align="center">图片链接</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">comment_num</td><td align="center">评论数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr></tbody></table><p>针对 weibo.com 站点，pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/eC391YSURN8BLV1Gcu0EJA">新版话题关键词爬虫发布</a> 。</p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><div class="note info simple"><p>在这里补充一点，如果需要设置多个关键词同时抓取，按照以下格式设置 keyword：</p><blockquote><p>“keyword”: “a b c”,</p></blockquote><p>实践证明，<strong>不需要空格</strong>也行，效果相同，爬的结果是多个关键词<strong>且</strong>的关系。</p></div><p>也可以参考视频教程：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=976177996&bvid=BV1A44y147PX&cid=427929738&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h3 id="转评赞系列"><a href="#转评赞系列" class="headerlink" title="转评赞系列"></a>转评赞系列</h3><p>针对指定微博的转发、评论和点赞信息抓取。</p><h4 id="评论爬虫"><a href="#评论爬虫" class="headerlink" title="评论爬虫"></a>评论爬虫</h4><p>评论数据尤为重要，先来讲讲评论抓取。</p><p>评论数据的抓取难度较大，针对一条 100w+ 评论的抓取，通常分为三个量级难度的抓取：0.1w、1w、10w。0.1w 指只能爬到几千条，10w 指的是能爬到几十万条。</p><p>本爬虫 针对 weibo.com ，能够保存的字段信息如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">字段值</th></tr></thead><tbody><tr><td align="center">parent_comment_id</td><td align="center">父评论 id，为空说明该评论就是根评论</td></tr><tr><td align="center">comment_id</td><td align="center">评论 id</td></tr><tr><td align="center">comment_time</td><td align="center">评论时间</td></tr><tr><td align="center">comment_user_name</td><td align="center">评论者昵称</td></tr><tr><td align="center">comment_user_link</td><td align="center">评论者主页链接</td></tr><tr><td align="center">comment_content</td><td align="center">评论内容</td></tr><tr><td align="center">comment_like_num</td><td align="center">评论点赞数</td></tr><tr><td align="center">child_comment_num</td><td align="center">子评论数，为 0 说明该评论可能就是子评论</td></tr></tbody></table><p>抓取数据量在第二量级，单条100w+ 的评论能抓到 1w-10w，当然，如果评论总量只有 10w，抓不到 10w。pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/t0S3u98HX62on3PGOnI78Q">新版评论爬虫发布</a> </p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><p>如果想要免费抓取最高量级的评论，可以参考 <a href="https://mp.weixin.qq.com/s/rc3S8lPyyz-tXf98CoXtLw">单机单账号抓取了单条微博的 100w+ 评论</a></p><h4 id="转发爬虫"><a href="#转发爬虫" class="headerlink" title="转发爬虫"></a>转发爬虫</h4><p>抓取指定微博的抓发信息，针对 weibo.com，抓取保存的字段如下：</p><table><thead><tr><th align="center">字段名</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">mid</td><td align="center">纯数字形式的微博唯一标识，可与字母+数字形式 id 互转</td></tr><tr><td align="center">publish_time</td><td align="center">发布时间</td></tr><tr><td align="center">user_name</td><td align="center">微博作者名</td></tr><tr><td align="center">user_link</td><td align="center">微博作者链接</td></tr><tr><td align="center">content</td><td align="center">内容</td></tr><tr><td align="center">weibo_link</td><td align="center">微博链接</td></tr><tr><td align="center">forward_num</td><td align="center">转发数</td></tr><tr><td align="center">like_num</td><td align="center">点赞数</td></tr></tbody></table><p>pyd 或者 pyc 获取及相关配置过程在 <a href="https://mp.weixin.qq.com/s/toPtFFFNKjyc5a4rrpBdwQ">新版转发爬虫发布</a> </p><div class="note info simple"><p>链接里相关配置流程可能更改，但是公众号文章无法多次修改，以最后获取的百度网盘链接里文件为准。</p></div><h4 id="点赞爬虫"><a href="#点赞爬虫" class="headerlink" title="点赞爬虫"></a>点赞爬虫</h4><p>看名字以为是手动点赞机器人，其实只是抓取点赞信息信息。</p><p>针对 m.weibo.cn，只能抓到最新的几千条点赞信息。</p><p>代码地址在：<a href="https://github.com/Python3Spiders/WeiboSuperSpider/blob/master/%E6%97%A0%20GUI%20%E5%8A%9F%E8%83%BD%E7%8B%AC%E7%AB%8B%E7%89%88/WeiboLikeSpider.py">WeiboLikeSpider.py</a> 。</p><p>详细信息及配置过程可以参考：<a href="https://mp.weixin.qq.com/s/JITHQK7mVaCIu2s1nPnMnw">新版点赞爬虫</a> 。</p><h3 id="位置签到系列"><a href="#位置签到系列" class="headerlink" title="位置签到系列"></a>位置签到系列</h3><p>针对 weibo.com，微博位置签到爬虫，只能抓取到最新 1000 余条，比较稳定，不多赘述，直接查看：<a href="https://mp.weixin.qq.com/s/KYcXsrwmIDyGDz1-lPKXmw">新版位置签到爬虫</a> 。</p><h3 id="超话系列"><a href="#超话系列" class="headerlink" title="超话系列"></a>超话系列</h3><p>针对 weibo.com，下载超话相册和抓取活跃粉丝，比较稳定，不多赘述，直接查看：<a href="https://mp.weixin.qq.com/s/bfFa3BQPIdfo2aLlR9i0ng">【开源】微博超话相册下载及超话活跃粉丝抓取</a> 。</p><h2 id="多功能集成爬虫"><a href="#多功能集成爬虫" class="headerlink" title="多功能集成爬虫"></a>多功能集成爬虫</h2><p>主要是针对上一步输出结果为微博信息，想要作为下一步或评论或转发输入的批量抓取，比如抓取一个微博话题下的所有评论，抓取一个用户发博的所有评论…以及其他 DIY 功能，FT 导向，本部分仍在活跃更新</p><h3 id="抓取话题下的所有评论"><a href="#抓取话题下的所有评论" class="headerlink" title="抓取话题下的所有评论"></a>抓取话题下的所有评论</h3><p>不只是话题，关键词也行，要求是输入为话题关键词爬虫的结果文件，输出为很多评论文件，也可合并之。</p><p>在上文所述[新版微博评论爬虫]中，只是针对单条微博的，如果是很多很多个微博需要爬评论，难道需要一个个输入 mid 和 uid 吗？考虑到这个问题，我特意写了个脚本，后，需要获取该话题下所有微博的评论，我们可以使用如下的 py 脚本代码自动构建视频中抓取评论所需要的 json 配置文件。</p><p>配套视频如下：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=336106792&bvid=BV13R4y1J7A7&cid=426114747&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><p>构建评论批量抓取配置文件的脚本附在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E7%94%9F%E6%88%90%E6%89%B9%E9%87%8F%E6%8A%93%E5%8F%96%E8%AF%84%E8%AE%BA%E7%9A%84-json-%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81">点我直达</a></p><h3 id="抓取用户发布微博的所有评论"><a href="#抓取用户发布微博的所有评论" class="headerlink" title="抓取用户发布微博的所有评论"></a>抓取用户发布微博的所有评论</h3><p>可以直接参考视频：</p><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">    <iframe src="//player.bilibili.com/player.html?aid=633890910&bvid=BV1zb4y1b7jV&cid=433966101&page=1"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe></div><h3 id="批量抓取转评赞"><a href="#批量抓取转评赞" class="headerlink" title="批量抓取转评赞"></a>批量抓取转评赞</h3><p>待更新…</p><h3 id="加字段"><a href="#加字段" class="headerlink" title="加字段"></a>加字段</h3><p>给一些 csv 加上学校，地区，性别等字段，总的来说还是需要上文 <a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF%E7%88%AC%E8%99%AB">用户信息爬虫</a>，待更新。</p><h3 id="下载图片"><a href="#下载图片" class="headerlink" title="下载图片"></a>下载图片</h3><p>就是说，爬虫结果文件里面的图片链接怎么下载到本地，代码贴在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87%E4%BB%A3%E7%A0%81">点我直达</a></p><h2 id="数据分析及可视化相关"><a href="#数据分析及可视化相关" class="headerlink" title="数据分析及可视化相关"></a>数据分析及可视化相关</h2><h3 id="微博评论情感分析"><a href="#微博评论情感分析" class="headerlink" title="微博评论情感分析"></a>微博评论情感分析</h3><p><code>pip install snownlp</code>；然后文末的代码随取随用：<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E8%AF%84%E8%AE%BA%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E4%BB%A3%E7%A0%81">点我直达</a></p><h3 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h3><p>代码附在文末，<a href="https://buyixiao.github.io/blog/weibo-super-spider.html#LDA%20%E4%BB%A3%E7%A0%81">点我直达</a> , 自行百度相关包安装过程，可能比较麻烦</p><h3 id="时间序列可视化"><a href="#时间序列可视化" class="headerlink" title="时间序列可视化"></a>时间序列可视化</h3><p><a href="https://buyixiao.github.io/blog/weibo-super-spider.html#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BB%A3%E7%A0%81">直达文末代码</a></p><h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><h3 id="为什么不做一个系统"><a href="#为什么不做一个系统" class="headerlink" title="为什么不做一个系统"></a>为什么不做一个系统</h3><p>以前尝试做过一个 GUI 系统，所有功能点击即可，后来微博改版，流程全部失效了，维护成本巨大，所以只关注基本功能。</p><h3 id="为什么有些-pyd-pyc-是付费的"><a href="#为什么有些-pyd-pyc-是付费的" class="headerlink" title="为什么有些 pyd/pyc 是付费的"></a>为什么有些 pyd/pyc 是付费的</h3><p>博主大厂全职，维护这个项目三年多，至少花费了我几百个小时的业余时间，为此熬过不少夜，废过不少食。所有设置了一些付费文章，3~9 块不等，算是对项目持续维护的激励，不是为文件付费，知悉。</p><h3 id="遇到错误怎么办"><a href="#遇到错误怎么办" class="headerlink" title="遇到错误怎么办"></a>遇到错误怎么办</h3><p>可以先查看 <a href="https://docs.qq.com/doc/DZGhYc0ZpcnB4TFVj">常见错误汇总</a>，没有找到答案的可以在本文文末评论。</p><h2 id="附录代码"><a href="#附录代码" class="headerlink" title="附录代码"></a>附录代码</h2><h3 id="微博两种-id-相互转化代码"><a href="#微博两种-id-相互转化代码" class="headerlink" title="微博两种 id 相互转化代码"></a>微博两种 id 相互转化代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/7/6 22:19</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> execjs</span><br><span class="line">jspython = <span class="string">&#x27;&#x27;&#x27;str62keys = &quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* 10进制值转换为62进制</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; int10 10进制值</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 62进制值</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function int10to62(int10) &#123;</span></span><br><span class="line"><span class="string">    var s62 = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    var r = 0;</span></span><br><span class="line"><span class="string">    while (int10 != 0) &#123;</span></span><br><span class="line"><span class="string">            r = int10 % 62;</span></span><br><span class="line"><span class="string">            s62 = this.str62keys.charAt(r) + s62;</span></span><br><span class="line"><span class="string">            int10 = Math.floor(int10 / 62);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return s62;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* 62进制值转换为10进制</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; str62 62进制值</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 10进制值</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function str62to10(str62) &#123;</span></span><br><span class="line"><span class="string">    var i10 = 0;</span></span><br><span class="line"><span class="string">    for (var i = 0; i &lt; str62.length; i++) &#123;</span></span><br><span class="line"><span class="string">            var n = str62.length - i - 1;</span></span><br><span class="line"><span class="string">            var s = str62.substr(i, 1);  // str62[i]; 字符串用数组方式获取，IE下不支持为“undefined”</span></span><br><span class="line"><span class="string">            i10 += parseInt(str62keys.indexOf(s)) * Math.pow(62, n);</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return i10;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* id转换为mid</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; id 微博id，如 &quot;201110410216293360&quot;</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 微博mid，如 &quot;wr4mOFqpbO&quot;</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function id2mid(id) &#123;</span></span><br><span class="line"><span class="string">    if (typeof (id) != &#x27;string&#x27;) &#123;</span></span><br><span class="line"><span class="string">            return false; // id数值较大，必须为字符串！</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    var mid = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    for (var i = id.length - 7; i &gt; -7; i = i - 7) //从最后往前以7字节为一组读取mid</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">            var offset1 = i &lt; 0 ? 0 : i;</span></span><br><span class="line"><span class="string">            var offset2 = i + 7;</span></span><br><span class="line"><span class="string">            var num = id.substring(offset1, offset2);</span></span><br><span class="line"><span class="string">            num = int10to62(num);</span></span><br><span class="line"><span class="string">            mid = num + mid;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return mid;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string">* mid转换为id</span></span><br><span class="line"><span class="string">* @param &#123;String&#125; mid 微博mid，如 &quot;wr4mOFqpbO&quot;</span></span><br><span class="line"><span class="string">* @return &#123;String&#125; 微博id，如 &quot;201110410216293360&quot;</span></span><br><span class="line"><span class="string">*/</span></span><br><span class="line"><span class="string">function mid2id(mid) &#123;</span></span><br><span class="line"><span class="string">    var id = &#x27;&#x27;;</span></span><br><span class="line"><span class="string">    for (var i = mid.length - 4; i &gt; -4; i = i - 4) //从最后往前以4字节为一组读取mid字符</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">            var offset1 = i &lt; 0 ? 0 : i;</span></span><br><span class="line"><span class="string">            var len = i &lt; 0 ? parseInt(mid.length % 4) : 4;</span></span><br><span class="line"><span class="string">            var str = mid.substr(offset1, len);</span></span><br><span class="line"><span class="string">            str = str62to10(str).toString();</span></span><br><span class="line"><span class="string">            if (offset1 &gt; 0) //若不是第一组，则不足7位补0</span></span><br><span class="line"><span class="string">            &#123;</span></span><br><span class="line"><span class="string">                    while (str.length &lt; 7) &#123;</span></span><br><span class="line"><span class="string">                            str = &#x27;0&#x27; + str;</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">            id = str + id;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    return id;</span></span><br><span class="line"><span class="string">&#125;&#x27;&#x27;&#x27;</span></span><br><span class="line">ctx = execjs.<span class="built_in">compile</span>(jspython) <span class="comment"># 编译 js</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mid2id</span>(<span class="params">mid</span>):</span></span><br><span class="line">    <span class="keyword">return</span> ctx.call(<span class="string">&#x27;mid2id&#x27;</span>, mid)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id2mid</span>(<span class="params"><span class="built_in">id</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> ctx.call(<span class="string">&#x27;id2mid&#x27;</span>, <span class="built_in">id</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">global</span> mid</span><br><span class="line">    mid = <span class="string">&#x27;L8J4vC6m7&#x27;</span></span><br><span class="line">    <span class="built_in">id</span> = mid2id(mid)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>)</span><br><span class="line">    <span class="built_in">id</span> = <span class="string">&#x27;4655725672138197&#x27;</span></span><br><span class="line">    mid = id2mid(<span class="built_in">id</span>)</span><br><span class="line">    <span class="built_in">print</span>(mid)</span><br></pre></td></tr></table></figure><h3 id="下载图片代码"><a href="#下载图片代码" class="headerlink" title="下载图片代码"></a>下载图片代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/11/2 20:48</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;易烊千玺V公益 - 文本.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">image_folder = <span class="string">&#x27;image&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(image_folder):</span><br><span class="line">    os.mkdir(image_folder)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;authority&#x27;</span>: <span class="string">&#x27;weibo.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;x-requested-with&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;content-type&#x27;</span>: <span class="string">&#x27;application/x-www-form-urlencoded&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;*/*&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-origin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://weibo.com/1192329374/KnnG78Yf3?filter=hot&amp;root_comment_id=0&amp;type=comment&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9,en-CN;q=0.8,en;q=0.7,es-MX;q=0.6,es;q=0.5&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cookie&#x27;</span>: <span class="string">&#x27;weibo.com 登录后随便哪一个接口的 cookie&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;index: <span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    image_urls = row[<span class="string">&#x27;img_urls&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">type</span>(image_urls) <span class="keyword">is</span> <span class="built_in">float</span> <span class="keyword">and</span> <span class="built_in">len</span>(image_urls) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> image_urls == <span class="string">&#x27;无&#x27;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;无&#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        image_url_list = image_urls.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> image_url_list:</span><br><span class="line">            <span class="built_in">print</span>(image_url)</span><br><span class="line">            image_spilt = image_url.rsplit(<span class="string">&#x27;.&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">            image_path = os.path.join(image_folder,</span><br><span class="line">                                      <span class="string">&#x27;&#123;&#125;.&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(hashlib.md5(image_spilt[<span class="number">0</span>].encode(<span class="string">&#x27;utf-8&#x27;</span>)).hexdigest(),</span><br><span class="line">                                                     image_spilt[<span class="number">1</span>]))</span><br><span class="line">            <span class="keyword">if</span> os.path.exists(image_path):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(image_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                response = requests.get(url=image_url, headers=headers)</span><br><span class="line">                fp.write(response.content)</span><br></pre></td></tr></table></figure><h3 id="生成批量抓取评论的-json-配置代码"><a href="#生成批量抓取评论的-json-配置代码" class="headerlink" title="生成批量抓取评论的 json 配置代码"></a>生成批量抓取评论的 json 配置代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2022/01/17 10:31</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">limit = <span class="number">100000</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> config_json_file <span class="keyword">as</span> config_path</span><br><span class="line"><span class="comment"># config_path = &#x27;mac_comment_config.json&#x27;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    config_json = json.loads(f.read())</span><br><span class="line">data_path = <span class="string">f&#x27;./topic/<span class="subst">&#123;config_json[<span class="string">&quot;keyword&quot;</span>]&#125;</span>.csv&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop_duplicate</span>(<span class="params">path, col=<span class="string">&quot;mid&quot;</span></span>):</span></span><br><span class="line">    df = pd.read_csv(path)</span><br><span class="line">    <span class="comment"># 去除重复行数据</span></span><br><span class="line">    df.drop_duplicates(keep=<span class="string">&#x27;first&#x27;</span>, inplace=<span class="literal">True</span>, subset=[col])</span><br><span class="line">    <span class="comment"># 可能还剩下重复 header</span></span><br><span class="line">    df = df[-df[col].isin([col])]</span><br><span class="line">    df.to_csv(path, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    drop_duplicate(data_path)</span><br><span class="line"></span><br><span class="line">    df = pd.read_csv(data_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清楚原有的 comments 配置，如不需要可注释</span></span><br><span class="line">    config_json[<span class="string">&#x27;comments&#x27;</span>].clear()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">        comment_num = row[<span class="string">&#x27;comment_num&#x27;</span>]</span><br><span class="line">        weibo_link = row[<span class="string">&#x27;weibo_link&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">int</span>(comment_num) &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;\n\n <span class="subst">&#123;weibo_link&#125;</span> 没有评论，不加入配置 json \n\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;?&#x27;</span> <span class="keyword">in</span> weibo_link:</span><br><span class="line">            weibo_link = weibo_link[:weibo_link.index(<span class="string">&#x27;?&#x27;</span>)]</span><br><span class="line">        uid = weibo_link[weibo_link.index(<span class="string">&#x27;com&#x27;</span>) + <span class="number">4</span>:weibo_link.rindex(<span class="string">&#x27;/&#x27;</span>)]</span><br><span class="line">        mid = weibo_link[weibo_link.rindex(<span class="string">&#x27;/&#x27;</span>) + <span class="number">1</span>:]</span><br><span class="line">        config_json[<span class="string">&#x27;comments&#x27;</span>].append(&#123;</span><br><span class="line">            <span class="string">&#x27;index&#x27;</span>: <span class="string">f&#x27;N<span class="subst">&#123;<span class="built_in">len</span>(config_json[<span class="string">&quot;comments&quot;</span>])&#125;</span>&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;mid&#x27;</span>: mid,</span><br><span class="line">            <span class="string">&#x27;uid&#x27;</span>: uid,</span><br><span class="line">            <span class="string">&#x27;limit&#x27;</span>: limit,</span><br><span class="line">            <span class="string">&#x27;user_name&#x27;</span>: row[<span class="string">&#x27;user_name&#x27;</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    config_json[<span class="string">&#x27;comments_pos&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n\n\n 共计 <span class="subst">&#123;<span class="built_in">len</span>(config_json[<span class="string">&#x27;comments&#x27;</span>])&#125;</span> 条微博加入评论抓取队列...  \n\n\n&quot;</span>)</span><br><span class="line">    sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(config_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(config_json, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="评论情感分析代码"><a href="#评论情感分析代码" class="headerlink" title="评论情感分析代码"></a>评论情感分析代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># create_time:      2021/11/2 9:50</span></span><br><span class="line"><span class="comment"># 运行环境           Python3.6+</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">初步想法</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1、评论者都是哪里人，echarts 地图</span></span><br><span class="line"><span class="string">2、评论者性别分布</span></span><br><span class="line"><span class="string">3、评论时间段分布，没必要分析，可能和发博时间有关？</span></span><br><span class="line"><span class="string">4、评论情感倾向</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_html</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(text) == <span class="number">0</span> <span class="keyword">or</span> text == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># text为包含html标签内容</span></span><br><span class="line">    content = re.sub(<span class="string">&quot;&lt;[^&gt;]*?&gt;&quot;</span>, <span class="string">&quot;&quot;</span>, text)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"></span><br><span class="line">text_sentiment_csv = <span class="string">&#x27;text_sentiment.csv&#x27;</span></span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentiment_score</span>(<span class="params">input_file, text_col = <span class="string">&#x27;text&#x27;</span></span>):</span></span><br><span class="line">    df = pd.read_csv(input_file)</span><br><span class="line">    sentiment_score_col = <span class="string">&#x27;sentiment_score&#x27;</span></span><br><span class="line">    is_scored_col = <span class="string">&#x27;has_scored&#x27;</span></span><br><span class="line">    df[is_scored_col] = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(df.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;index + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;df.shape[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> row[is_scored_col] == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        text = row[text_col]</span><br><span class="line">        <span class="comment"># 去除 html 标签</span></span><br><span class="line">        text = filter_html(text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(text) == <span class="number">0</span> <span class="keyword">or</span> text == <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 本行没有文本</span></span><br><span class="line">            sentiment = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sentiment = SnowNLP(text).sentiments</span><br><span class="line"></span><br><span class="line">        df.loc[index, sentiment_score_col] = sentiment</span><br><span class="line">        df.loc[index, is_scored_col] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    df.to_csv(input_file, index=<span class="literal">False</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sentiment_score(text_sentiment_csv)</span><br></pre></td></tr></table></figure><h3 id="LDA-代码"><a href="#LDA-代码" class="headerlink" title="LDA 代码"></a>LDA 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># author:           inspurer(月小水长)</span></span><br><span class="line"><span class="comment"># pc_type           lenovo</span></span><br><span class="line"><span class="comment"># create_time:      2020/9/20 13:35</span></span><br><span class="line"><span class="comment"># file_name:        main.py</span></span><br><span class="line"><span class="comment"># github            https://github.com/inspurer</span></span><br><span class="line"><span class="comment"># qq邮箱            2391527690@qq.com</span></span><br><span class="line"><span class="comment"># 微信公众号         月小水长(ID: inspurer)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> LatentDirichletAllocation</span><br><span class="line"><span class="keyword">import</span> pyLDAvis.sklearn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">doLDA</span>(<span class="params">content, n_features=<span class="number">1000</span>, n_topics=<span class="number">5</span>, max_df=<span class="number">5</span>, min_df=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="comment"># 向量化</span></span><br><span class="line">    n_features = n_features</span><br><span class="line"></span><br><span class="line">    tf_vectorizer = CountVectorizer(strip_accents=<span class="string">&#x27;unicode&#x27;</span>,</span><br><span class="line">                                    max_features=n_features,</span><br><span class="line">                                    stop_words=<span class="string">&#x27;english&#x27;</span>,</span><br><span class="line">                                    max_df=max_df,</span><br><span class="line">                                    min_df=min_df)</span><br><span class="line">    tf = tf_vectorizer.fit_transform(content)</span><br><span class="line"></span><br><span class="line">    n_topics = n_topics</span><br><span class="line">    <span class="comment"># LDA 处理</span></span><br><span class="line">    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=<span class="number">50</span>,</span><br><span class="line">                                    learning_method=<span class="string">&#x27;online&#x27;</span>,</span><br><span class="line">                                    learning_offset=<span class="number">50.</span>,</span><br><span class="line">                                    random_state=<span class="number">0</span>)</span><br><span class="line">    lda.fit(tf)</span><br><span class="line"></span><br><span class="line">    data = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    pyLDAvis.show(data)  <span class="comment"># 可视化主题模型</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&#x27;comments.csv&#x27;</span>)</span><br><span class="line">    doLDA(content=df[<span class="string">&#x27;content&#x27;</span>].values.tolist(),n_topics=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="时间序列可视化代码"><a href="#时间序列可视化代码" class="headerlink" title="时间序列可视化代码"></a>时间序列可视化代码</h3><p>正在更新中…</p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>本文首发： <a href="https://buyixiao.github.io/blog/weibo-super-spider.html">BuyiXiao’s Blog</a></p><p>链接地址：<a href="https://buyixiao.github.io/blog/weibo-super-spider.html">https://buyixiao.github.io/blog/weibo-super-spider.html</a></p><p>转载需注明来源。</p><p>如本项目对你有很多帮助，可以点击下方打赏赞助我持续维护。</p>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微博评论 </tag>
            
            <tag> weibosuperspider </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> python </tag>
            
            <tag> 用户微博 </tag>
            
            <tag> 微博转发 </tag>
            
            <tag> 微博点赞 </tag>
            
            <tag> 微博签到 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【持续更新 | 2022最新】基于 hexo 的 butterfly 优化教程</title>
      <link href="/blog/butterfly-beauty-quick-start.html"/>
      <url>/blog/butterfly-beauty-quick-start.html</url>
      
        <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>博主 2018/06/07 配置了一个基于 hexo + next 的博客：<a href="https://inspurer.github.io/">月小水长的个人博客</a>，维护几年有余后，源码或配置暂时丢失，于 2022/01/16 新开了 <a href="https://buyixiao.github.io/">BuyiXiao’s Blog</a> ，算是新的博客旅程，兴许日后会在 <a href="https://inspurer.github.io/">月小水长的个人博客</a> 继续更新…</p><p>本站点基于 hexo 6.0 + butterfly 4.0.1，本文记述了新博客配置过程的点点滴滴，就如文章摘要所述，<strong>不是臃肿的流水教程，但是小而精的查漏补缺，以及记录常见易错点</strong>。有问题欢迎留言</p><h2 id="hexo-基础配置及-butterfly-基础美化"><a href="#hexo-基础配置及-butterfly-基础美化" class="headerlink" title="hexo 基础配置及 butterfly 基础美化"></a>hexo 基础配置及 butterfly 基础美化</h2><h3 id="官方-quick-start"><a href="#官方-quick-start" class="headerlink" title="官方 quick-start"></a>官方 quick-start</h3><p>博主第一次搭建博客时，收藏了很多 hexo + next 的教程，但是由于站点或主题的不断迭代升级，很多教程都失效了，所以建议基础部分直接看官方最新的教程。</p><div class="note default modern"><p><a href="https://hexo.io/docs/">hexo 框架官方文档</a></p></div><div class="note success simple"><p><a href="https://butterfly.js.org/">butterfly 主题官方教程</a></p></div><h3 id="hexo-常见命令"><a href="#hexo-常见命令" class="headerlink" title="hexo 常见命令"></a>hexo 常见命令</h3><p>1、 hexo init</p><p>创建一个 buyixiao 文件夹并初始化为 hexo 目录</p><blockquote><p>hexo init buyixiao<br>cd buyixiao</p></blockquote><p>2、hexo generate<br>hexo generate 命令用于生成静态文件，一般可以简写为 hexo g</p><blockquote><p>-d 选项，指定生成后部署，与 hexo d -g 等价</p></blockquote><p>3、hexo server<br>hexo server 命令用于启动本地服务器，一般可以简写为 hexo s</p><blockquote><p>-p 选项，指定服务器端口，默认为 4000</p></blockquote><blockquote><p>-i 选项，指定服务器 IP 地址，默认为 0.0.0.0</p></blockquote><blockquote><p>-s 选项，静态模式 ，仅提供 public 文件夹中的文件并禁用文件监视</p></blockquote><p>本地运行服务器前需要安装 hexo-server 插件</p><blockquote><p>npm install hexo-server –save</p></blockquote><p>4、hexo deploy<br>hexo deploy 命令用于部署网站，一般可以简写为 hexo d</p><blockquote><p>-g 选项，指定生成后部署，与 hexo g -d 等价</p></blockquote><p>5、hexo clean<br>hexo clean 命令用于清理缓存文件，是一个比较常用的命令</p><p>6、hexo –safe<br>hexo –safe 表示安全模式，用于禁用加载插件和脚本</p><p>7、hexo 新建文章</p><blockquote><p>hexo new “这里填入文章的标题”</p></blockquote><h2 id="一些-Tips"><a href="#一些-Tips" class="headerlink" title="一些 Tips"></a>一些 Tips</h2><h3 id="valine-的-placeholder-和-requiredFields-无效"><a href="#valine-的-placeholder-和-requiredFields-无效" class="headerlink" title="valine 的 placeholder 和 requiredFields 无效"></a>valine 的 placeholder 和 requiredFields 无效</h3><div class="note success simple"><p>应该是看了很早的教程，最新的 butterfly 这两个字段应该放在 option 下一级而不是和  option 平级。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">option:</span></span><br><span class="line">  <span class="attr">placeholder:</span> <span class="string">send</span> <span class="string">from</span> <span class="string">buyixiao&#x27;s</span> <span class="string">blog</span></span><br><span class="line">  <span class="attr">requiredFields:</span> [<span class="string">&#x27;nick&#x27;</span>,<span class="string">&#x27;mail&#x27;</span>]</span><br></pre></td></tr></table></figure></div><h3 id="删除-valine-垃圾评论"><a href="#删除-valine-垃圾评论" class="headerlink" title="删除 valine 垃圾评论"></a>删除 valine 垃圾评论</h3><div class="note success simple"><p>很简单，直接去 LeanCloud 后台数据库界面删除对应评论即可。</p></div><h3 id="删除文章"><a href="#删除文章" class="headerlink" title="删除文章"></a>删除文章</h3><div class="note success simple"><p>很简单，直接去站点根目录 <code>source/_posts</code> 文件夹中删除文章 md 再 再 <code>hexo clean</code> &amp;<code>hexo g -d</code>。</p></div><h3 id="文章配置多个-tag"><a href="#文章配置多个-tag" class="headerlink" title="文章配置多个 tag"></a>文章配置多个 tag</h3><div class="note success simple"><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags:</span> [<span class="string">butterfly</span>,<span class="string">hexo</span>,<span class="string">beauty</span>]</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tags:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">butterfly</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hexo</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">beauty</span></span><br></pre></td></tr></table></figure></div><h3 id="文章自定义-url"><a href="#文章自定义-url" class="headerlink" title="文章自定义 url"></a>文章自定义 url</h3><p>如何像 <a href="https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html">https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html</a> 一样，加一个前缀 blog？</p><div class="note success simple"><p>在 站点配置文件中搜 permalink</p><p>原来的是这样的，</p><blockquote><p>permalink: :year/:month/:day/:title/</p></blockquote><p>我们改成</p><blockquote><p>permalink: blog/:title_en/</p></blockquote><p>然后在写文章的 md 中加入</p><blockquote><p>title_en: my-defined-url</p></blockquote><p>就能在浏览器通过以下地址访问了</p><blockquote><p>{username}.github.io/blog/my-defined-url</p></blockquote></div><h3 id="文章修改预设-formats"><a href="#文章修改预设-formats" class="headerlink" title="文章修改预设 formats"></a>文章修改预设 formats</h3><div class="note success simple"><p>打开站点根目录下的 scaffolds 文件夹，修改里面的 post.md 即可，page formates 同理</p></div><h2 id="配置美化过程中那些拦路虎"><a href="#配置美化过程中那些拦路虎" class="headerlink" title="配置美化过程中那些拦路虎"></a>配置美化过程中那些拦路虎</h2><p>记录填坑之路，标题是错误，正文是解决办法。</p><h3 id="OpenSSL-SSL-read-Connection-was-reset-errno-10054"><a href="#OpenSSL-SSL-read-Connection-was-reset-errno-10054" class="headerlink" title="OpenSSL SSL_read: Connection was reset, errno 10054"></a>OpenSSL SSL_read: Connection was reset, errno 10054</h3><div class="note success simple"><p>在站点配置 git 仓库地址时使用 ssh 地址，不要使用 https 地址。</p></div><h3 id="本地和-github-io-访问不一致"><a href="#本地和-github-io-访问不一致" class="headerlink" title="本地和 github.io 访问不一致"></a>本地和 github.io 访问不一致</h3><div class="note success simple"><p>可能是浏览器有缓存，使用 ctrl + f5 刷新试试。</p><p>如果是本次部署没有任何文章更新，github page 没有识别到文章相关更新，也有可能导致这个问题，建议新建或修改文章时间。</p></div><h3 id="clone-主题时超时"><a href="#clone-主题时超时" class="headerlink" title="clone 主题时超时"></a>clone 主题时超时</h3><div class="note success simple"><p>原因是 github 的 dns 被污染了，打开 <code>C:\Windows\System32\drivers\etc</code> 下的 hosts 文件，配置 github 的 dns 解析。格式如下：</p></div><blockquote><p>140.82.113.3  github.com git<br>199.232.69.194 github.global.ssl.fastly.net<br>185.199.108.153 assets-cdn.github.com</p></blockquote><p>前面的 dns 地址可能需要更换，详情可以参考 <a href="https://blog.csdn.net/ygdxt/article/details/82825013">github 打开很慢的解决办法</a></p><h3 id="butterfly-主题报错-extends-includes-layout-pug-block-content-include…"><a href="#butterfly-主题报错-extends-includes-layout-pug-block-content-include…" class="headerlink" title="butterfly 主题报错 extends includes/layout.pug block content include…"></a>butterfly 主题报错 extends includes/layout.pug block content include…</h3><p>错误具体信息如下</p><div class="note warning simple"><p>extends includes/layout.pug block content include ./includes/mixins/post-ui.pug #recent-posts.recent-posts +postUI include includes/pagination.pug</p></div><p>解决办法是输入命令</p><div class="note success simple"><p>npm install –save hexo-renderer-jade hexo-generator-feed hexo-generator-sitemap hexo-browsersync hexo-generator-archive</p></div><p>再 <code>hexo clean</code> &amp;<code>hexo g -d</code> 就好了。</p><h3 id="butterfly-主题报错-if-theme-newest-comments-enable-xxx-read"><a href="#butterfly-主题报错-if-theme-newest-comments-enable-xxx-read" class="headerlink" title="butterfly 主题报错 if theme.newest_comments.enable xxx read"></a>butterfly 主题报错 if theme.newest_comments.enable xxx read</h3><div class="note warning simple"><p>if theme.newest_comments.enable xxx read…</p><p>Cannot read property ‘0’ of null…</p></div><div class="note success simple"><p>原因是，没有配置 comment 就把 newset_comment 开关打开了。</p></div><h3 id="列表页-newset-评论无法显示，文章内评论可以"><a href="#列表页-newset-评论无法显示，文章内评论可以" class="headerlink" title="列表页 newset 评论无法显示，文章内评论可以"></a>列表页 newset 评论无法显示，文章内评论可以</h3><div class="note success simple"><p>情况发生于 Valine 评论系统，解决办法是配置下 serverURLs 为 LeanCloud 提供的 RestAPI 地址。</p></div><h3 id="配置了但是-addtothis-分享系统无效"><a href="#配置了但是-addtothis-分享系统无效" class="headerlink" title="配置了但是 addtothis 分享系统无效"></a>配置了但是 addtothis 分享系统无效</h3><div class="note success simple"><p>应该是没有在 addtothis 后台新建 share_button，选择相应的分享平台并激活按钮。</p></div><h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>本文链接：<a href="https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html">https://buyixiao.github.io/blog/butterfly-beauty-quick-start.html</a></p><p>转载或引用需要注明来源。</p>]]></content>
      
      
      <categories>
          
          <category> Butterfly </category>
          
      </categories>
      
      
        <tags>
            
            <tag> butterfly </tag>
            
            <tag> hexo </tag>
            
            <tag> beauty </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pip install 成功了，import 却出错了</title>
      <link href="/blog/pip-install-success-import-fail.html"/>
      <url>/blog/pip-install-success-import-fail.html</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>可能不少人遇到这样的问题，为什么在 cmd 命令行中 <code>pip install requests</code> 成功了，在 Pycharm 中写代码 <code>import requests</code> 还是报 module not found 错误，装是装上了，又没完全装上，何哉？下面以 requests 这个库为例子，详细说明原因及解决办法。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>根本原因是，<strong>没有认识处理好 python 多版本共存问题，cmd 里装 requests 的 python 环境不是你 pycharm 里面运行的那个 python 环境</strong>。</p><p>在 cmd 输入 <code>pip install requests</code> 前，不妨先输入一个命令，查看有哪些 Python 环境：<code>where python</code></p><p>cmd 显示如下，可以看到，电脑有三个 python 环境，当在命令行输入 python 时，默认进入了第一个 Python36_64 环境，这样的顺序是由编辑系统环境变量的先后顺序决定的</p><blockquote><p>D:\a\b\c\Python36_64\python.exe<br>D:\c\b\a\Python388\python.exe<br>C:\x\y\z\python.exe</p></blockquote><p>然后查看有哪些 pip ：<code>where pip</code></p><blockquote><p>D:\a\b\c\Python36_64\Scripts\pip.exe<br>D:\c\b\a\Python388\Scripts\pip.exe</p></blockquote><p>在 cmd 输入 <code>pip install requests</code> 时，只会给环境变量中从上到下第一个 pip 对应的 Python 环境装的，也就是给 Python36_64 这个环境装的。</p><p>然后看下 Pycharm 中是不是也用的这个 Python 环境，点击菜单栏的 File – Settings</p><p><img src="https://s2.loli.net/2022/01/17/XOf9cv1mFn2wxGa.png" alt="Pycharm 查看 Python 环境.png"></p><p>展开 Python Interpreter，可以看到就是 cmd 里默认的 Python36_64 环境，点击上图中右上角的锯齿状设置按钮，可以给 Pycharm 切换 python 环境。然后这些增删操作看符号就知道了，不赘述。</p><p>如果选中了想要的 python 环境，可以点击上图左下角中的 + 号按钮，搜索 requests 包，点击并安装。</p><p><img src="https://s2.loli.net/2022/01/17/4f9vmuiNy1jL7hC.png" alt="Pycharm 安装库.png"></p><h2 id="cmd-和-Pycharm-换源"><a href="#cmd-和-Pycharm-换源" class="headerlink" title="cmd 和 Pycharm 换源"></a>cmd 和 Pycharm 换源</h2><p>由于某些原因 python 库默认的下载地址下载很慢，在 cmd 中可以依次输入以面命令切换成 douban 源，下载安装就起飞了</p><blockquote><p>pip install pqi<br>pqi use douban</p></blockquote><p>在 Pycharm 中也有等同操作，点击上一个图中的 Manage Repositories ，将 <a href="https://pypi.python.com/simple/">https://pypi.python.com/simple/</a> 修改成   <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a> ，并且一路 OK 确定即可。</p><p>最后再回到 cmd 中</p><blockquote><p>D:\a\b\c\Python36_64\Scripts\pip.exe<br>D:\c\b\a\Python388\Scripts\pip.exe</p></blockquote><p>如果想要快速给第二个 Python388 装 requests，该怎么办呢？我们在文件夹中打开 D:\c\b\a\Python388\Scripts 这个路径。</p><p><img src="https://s2.loli.net/2022/01/17/4GBIcQFVr7dijKU.png" alt="pip 目录"></p><p>我们可以直接在 cmd 中通过 <code>pip3.8 install requests</code> 给这个环境装 requests；</p><p>也可以复制一个 pip.exe，并粘贴命名为 pipenv.exe，<code>pipenv install requests</code>；</p><p>除了 pip3.8 是这个环境独有的，其他两个 pip.exe 和 pip3.exe 在 python36_64 那个环境也有，所以 pip/pip3 命令会被在环境变量中优先级高的 python36_64 的 pip 接管。</p><h2 id="如何避免这种问题"><a href="#如何避免这种问题" class="headerlink" title="如何避免这种问题"></a>如何避免这种问题</h2><p>在系统中只装一个版本的 Python，本着一个项目一个虚拟环境的原则，每次新建项目，用系统的 Python 复制出一个虚拟环境，起个和项目相关的环境名，然后在 Pycharm 选择虚拟环境目录下，Scripts 文件夹下的 python.exe 作为项目的解析器。</p><p>Windows 下创建虚拟环境步骤如下：</p><h4 id="安装-virtualenv"><a href="#安装-virtualenv" class="headerlink" title="安装 virtualenv"></a>安装 virtualenv</h4><blockquote><p>pip install virtualenv</p></blockquote><h4 id="在当前目录下创建虚拟环境"><a href="#在当前目录下创建虚拟环境" class="headerlink" title="在当前目录下创建虚拟环境"></a>在当前目录下创建虚拟环境</h4><blockquote><p>virtualenv env_crawl</p></blockquote><h4 id="激活、退出虚拟环境"><a href="#激活、退出虚拟环境" class="headerlink" title="激活、退出虚拟环境"></a>激活、退出虚拟环境</h4><p>在 cmd 中需要 cd 进入到虚拟环境目录下 Script 文件</p><p>夹中，使用下述命令激活</p><blockquote><p>activate</p></blockquote><p>当然，如果不在 Script 下，但在当前盘符中，使用</p><blockquote><p>./xxx/yyy activate</p></blockquote><p>这种相对路径格式也是可以的。</p><p>激活之后，cmd 会在 path 最前面显示一个 <strong>（{env_crawl})</strong> ，在当前 cmd 会话中 Python 相关的操作都是针对这个虚拟环境而言的，操作和修改不会影响其他 Python 环境。如果想要退出环境，只需要使用</p><blockquote><p>deactivate</p></blockquote><p>值得欣喜的是，<strong>如果在 Pycharm 选择中虚拟环境，那么在 Pycharm 中打开终端，就可以直接进入到了当前的并且是已经激活的虚拟环境</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pip </tag>
            
            <tag> pycharm </tag>
            
            <tag> 换源 </tag>
            
            <tag> requests </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写在 BuyiXiao&#39;s Blog 开始</title>
      <link href="/blog/why-buyixiao-blog-start.html"/>
      <url>/blog/why-buyixiao-blog-start.html</url>
      
        <content type="html"><![CDATA[<h2 id="who-is-buyixiao"><a href="#who-is-buyixiao" class="headerlink" title="who is buyixiao"></a>who is buyixiao</h2><p>buyixiao 行不改名，坐不改姓；江湖人称 <font color="red">肖不已</font>，或者 <font color="red">布衣肖</font>；三尺微命，一介书生，不足挂齿。<br>buyixiao 在这个互联网中还有其他两个亲兄弟，一个叫 <a href="https://inspurer.github.io/">inspurer</a>，还有一个叫 <a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzUzMDE5MzQ3Ng==#wechat_redirect">月小水长</a>。</p><h2 id="buyixiao’s-skills"><a href="#buyixiao’s-skills" class="headerlink" title="buyixiao’s skills"></a>buyixiao’s skills</h2><p>写过数据分析可视化，会一点爬虫，前 Android 不知名工程师，上线过小程序和 Chrome 扩展，还是一个 Python 全沾工程师…</p><p>之前在某大厂干过开发，现在在家里睡大觉。</p><h2 id="buyixiao’s-blog"><a href="#buyixiao’s-blog" class="headerlink" title="buyixiao’s blog"></a>buyixiao’s blog</h2><p>关于为什么要开这个 blog，有两个原因。</p><p>第一层次的原因是，buyixiao 之前在公众号更新文章，但是该生态比较封闭，而且无法很好修改发布过的文章，还有其他各种限制，所以急切需要一个自主可控的博客系统。</p><p>另一个是因为，buyixiao 老大哥  <a href="https://inspurer.github.io/">inspurer 的个人博客</a> 源代码已经不可考了，而且网站历史包袱太重，包括样式，渲染速度等都积重难返了，所以有 <a href="https://buyixiao.github.io/">buyixiao’s blog</a> 弟承兄业。</p><p>所以这篇文章，还是有一点序的意思。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> buyixiao </tag>
            
            <tag> inspurer </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
